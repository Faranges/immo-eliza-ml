{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "def1695a",
   "metadata": {},
   "source": [
    "### Add the province column back to filtered_final_cleaned_data.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9320d994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   postal_code province\n",
      "0         2800  Antwerp\n",
      "1         2200  Antwerp\n",
      "2         2840  Antwerp\n",
      "3         2440  Antwerp\n",
      "4         2300  Antwerp\n",
      "CSV saved with 'province' column!\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "import pandas as pd\n",
    "\n",
    "\"\"\"We need to add a \"province\" column to our filtered_final_cleaned_data.csv file. \n",
    "Since we only have postal codes, we'll first need to map them to their provinces. \n",
    "We'll use a dictionary mapping postal codes to provinces.\"\"\"\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(\"../data/raw/filtered_final_cleaned_data.csv\")\n",
    "\n",
    "# Define postal code ranges per province\n",
    "postal_to_province = {\n",
    "    \"Antwerp\": range(2000, 3000),\n",
    "    \"East-Flanders\": range(9000, 10000),\n",
    "    \"West-Flanders\": range(8000, 9000),\n",
    "    \"Flemish-Brabant\": list(range(1500, 2000)) + list(range(3000, 3500)),\n",
    "    \"Brussels\": range(1000, 1300),\n",
    "    \"Limburg\": range(3500, 4000),\n",
    "    \"Liège\": range(4000, 5000),\n",
    "    \"Namur\": range(5000, 6000),\n",
    "    \"Hainaut\": list(range(6000, 6600)) + list(range(7000, 8000)),\n",
    "    \"Luxembourg\": range(6600, 7000),\n",
    "    \"Brabant-Wallon\": range(1300, 1500)\n",
    "}\n",
    "\n",
    "# Helper function to find province for each postal code\n",
    "def get_province(postal_code):\n",
    "    try:\n",
    "        postal_code = int(postal_code)\n",
    "        for province, codes in postal_to_province.items():\n",
    "            if postal_code in codes:\n",
    "                return province\n",
    "        return \"Unknown\"\n",
    "    except:\n",
    "        return \"Unknown\"\n",
    "\n",
    "\n",
    "# Apply the function to create a new column called \"province\" with the province names based on the postal codes.\n",
    "df[\"province\"] = df[\"postal_code\"].apply(get_province)\n",
    "\n",
    "print(df[[\"postal_code\", \"province\"]].head())\n",
    "\n",
    "# display(df.head())\n",
    "\n",
    "# Save the updated dataset\n",
    "df.to_csv(\"../data/raw/filtered_final_cleaned_data.csv\", index=False)\n",
    "print(\"CSV saved with 'province' column!\")\n",
    "\n",
    "# Load the new dataset with province column\n",
    "df = pd.read_csv(\"../data/raw/filtered_final_cleaned_data.csv\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38adfdfb",
   "metadata": {},
   "source": [
    "### Bring together and see your fully preprocessed dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e6da06",
   "metadata": {},
   "source": [
    "All preprocessing steps are applied to X_train and X_test, not the original df.\n",
    "So the original df will remain:\n",
    "with NaNs\n",
    "not encoded\n",
    "not scaled\n",
    "This is expected — sklearn never modifies the original DataFrame.\n",
    "\n",
    "Most sklearn transformers (OneHotEncoder, StandardScaler, etc.) output NumPy arrays, which:\n",
    "don’t keep column names,\n",
    "don’t automatically merge back into X_train,\n",
    "won’t be visible in df.head().\n",
    "Unless you explicitly rebuild a DataFrame with the transformed results, nothing changes.\n",
    "\n",
    "How to see your fully preprocessed dataset:   \n",
    "you must manually combine the transformed arrays back into a DataFrame:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a1c4d6",
   "metadata": {},
   "source": [
    "Option A — Using ColumnTransformer + Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d367b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit on train\n",
    "X_train_processed = preprocessor.fit_transform(X_train)\n",
    "\n",
    "# Transform test\n",
    "X_test_processed = preprocessor.transform(X_test)\n",
    "\n",
    "# Turn into DataFrame\n",
    "processed_cols = preprocessor.get_feature_names_out()\n",
    "\n",
    "X_train_final = pd.DataFrame(X_train_processed, columns=processed_cols, index=X_train.index)\n",
    "X_test_final = pd.DataFrame(X_test_processed, columns=processed_cols, index=X_test.index)\n",
    "\n",
    "X_train_final.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92058c79",
   "metadata": {},
   "source": [
    "Option B — doing everything manually:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5dd08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Impute\n",
    "X_train[\"living_area\"] = imputer.fit_transform(X_train[[\"living_area\"]])\n",
    "X_test[\"living_area\"] = imputer.transform(X_test[[\"living_area\"]])\n",
    "\n",
    "# 2. Encode\n",
    "ohe = OneHotEncoder(sparse_output=False)\n",
    "encoded = ohe.fit_transform(X_train[[\"province\"]])\n",
    "cols = ohe.get_feature_names_out([\"province\"])\n",
    "X_train_encoded = pd.DataFrame(encoded, columns=cols, index=X_train.index)\n",
    "\n",
    "# 3. Scale\n",
    "scaler = StandardScaler()\n",
    "scaled = scaler.fit_transform(X_train[[\"living_area\"]])\n",
    "X_train_scaled = pd.DataFrame(scaled, columns=[\"living_area_scaled\"], index=X_train.index)\n",
    "\n",
    "# 4. Combine everything\n",
    "X_train_final = pd.concat([X_train, X_train_encoded, X_train_scaled], axis=1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
