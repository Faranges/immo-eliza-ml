{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9751dda9",
   "metadata": {},
   "source": [
    "# PREPROCESSING PIPELINE FOR LINEAR REGRESSION MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b0a8941",
   "metadata": {},
   "source": [
    "Preprocessing pipeline to get a fully transformed (imputed - encoded - scaled) X_train_final and X_test_final. Keeps original X_train and X_test intact.\n",
    "DataFrames containing ALL new columns, concatenated together cleanly and safely to avoid data leakage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf55c25",
   "metadata": {},
   "source": [
    "## 1. Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3bb9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "import pandas as pd\n",
    "\n",
    "# --- NUMERICAL IMPUTATION (mean) ---\n",
    "num_cols = X_train.select_dtypes(include=[\"int64\", \"float64\"]).columns\n",
    "\n",
    "num_imputer = SimpleImputer(strategy=\"mean\")\n",
    "\n",
    "X_train_num = pd.DataFrame(\n",
    "    num_imputer.fit_transform(X_train[num_cols]),\n",
    "    columns=num_cols,\n",
    "    index=X_train.index\n",
    ")\n",
    "\n",
    "X_test_num = pd.DataFrame(\n",
    "    num_imputer.transform(X_test[num_cols]),\n",
    "    columns=num_cols,\n",
    "    index=X_test.index\n",
    ")\n",
    "\n",
    "# --- CATEGORICAL IMPUTATION FOR state_of_building ---\n",
    "X_train_cat = X_train.copy()\n",
    "X_test_cat = X_test.copy()\n",
    "\n",
    "X_train_cat[\"state_of_building\"] = X_train_cat[\"state_of_building\"].fillna(\"unknown\")\n",
    "X_test_cat[\"state_of_building\"] = X_test_cat[\"state_of_building\"].fillna(\"unknown\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5535458",
   "metadata": {},
   "source": [
    "## 2. Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "549237cd",
   "metadata": {},
   "source": [
    "### One Hot Encoding for 'type' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5403c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "ohe_type = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)\n",
    "\n",
    "type_train = ohe_type.fit_transform(X_train_cat[[\"type\"]])\n",
    "type_test = ohe_type.transform(X_test_cat[[\"type\"]])\n",
    "\n",
    "type_train_df = pd.DataFrame(\n",
    "    type_train,\n",
    "    columns=ohe_type.get_feature_names_out([\"type\"]),\n",
    "    index=X_train.index\n",
    ")\n",
    "\n",
    "type_test_df = pd.DataFrame(\n",
    "    type_test,\n",
    "    columns=ohe_type.get_feature_names_out([\"type\"]),\n",
    "    index=X_test.index\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "983c188d",
   "metadata": {},
   "source": [
    "### One Hot Encoding for \"province\" column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93c35c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe_province = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)\n",
    "\n",
    "province_train = ohe_province.fit_transform(X_train_cat[[\"province\"]])\n",
    "province_test = ohe_province.transform(X_test_cat[[\"province\"]])\n",
    "\n",
    "province_train_df = pd.DataFrame(\n",
    "    province_train,\n",
    "    columns=ohe_province.get_feature_names_out([\"province\"]),\n",
    "    index=X_train.index\n",
    ")\n",
    "\n",
    "province_test_df = pd.DataFrame(\n",
    "    province_test,\n",
    "    columns=ohe_province.get_feature_names_out([\"province\"]),\n",
    "    index=X_test.index\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f98fd65b",
   "metadata": {},
   "source": [
    "### LabelEncoding for \"subtype\" column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6368f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le_subtype = LabelEncoder()\n",
    "\n",
    "subtype_train = le_subtype.fit_transform(X_train_cat[\"subtype\"])\n",
    "subtype_test = le_subtype.transform(X_test_cat[\"subtype\"])\n",
    "\n",
    "subtype_train_df = pd.DataFrame({\"subtype_le\": subtype_train}, index=X_train.index)\n",
    "subtype_test_df = pd.DataFrame({\"subtype_le\": subtype_test}, index=X_test.index)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "849441d1",
   "metadata": {},
   "source": [
    "### OrdinalEncoder for \"state_of_building\" column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228671cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "import pandas as pd\n",
    "\n",
    "# 1. Define the custom order\n",
    "state_order = [\n",
    "    [\n",
    "        \"unknown\",\n",
    "        \"To demolish\",\n",
    "        \"Under construction\",\n",
    "        \"To restore\",\n",
    "        \"To renovate\",\n",
    "        \"To be renovated\",\n",
    "        \"Normal\",\n",
    "        \"Fully renovated\",\n",
    "        \"Excellent\",\n",
    "        \"New\"\n",
    "    ]\n",
    "]\n",
    "\n",
    "# 2. Create the encoder\n",
    "ord_enc = OrdinalEncoder(categories=state_order)\n",
    "\n",
    "# 3. Fit on training data only\n",
    "state_train = ord_enc.fit_transform(X_train_cat[[\"state_of_building\"]])\n",
    "state_test = ord_enc.transform(X_test_cat[[\"state_of_building\"]])\n",
    "\n",
    "# 4. Convert to DataFrames\n",
    "# Why flatten()? OrdinalEncoder returns a 2-D array with shape (n_rows, 1). But a DataFrame column needs a 1-D array.\n",
    "# So this turns it into a proper single column\n",
    "state_train_df = pd.DataFrame(\n",
    "    {\"state_oe\": state_train.flatten()},\n",
    "    index=X_train.index\n",
    ")\n",
    "\n",
    "state_test_df = pd.DataFrame(\n",
    "    {\"state_oe\": state_test.flatten()},\n",
    "    index=X_test.index\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb55482d",
   "metadata": {},
   "source": [
    "## 3. Scaling (Standardization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9532e702",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scale_cols = [\"living_area (m²)\", \"number_of_bedrooms\", \"number_facades\", \"terrace_area (m²)\"]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = pd.DataFrame(\n",
    "    scaler.fit_transform(X_train_num[scale_cols]),\n",
    "    columns=[col + \"_scaled\" for col in scale_cols],\n",
    "    index=X_train.index\n",
    ")\n",
    "\n",
    "X_test_scaled = pd.DataFrame(\n",
    "    scaler.transform(X_test_num[scale_cols]),\n",
    "    columns=[col + \"_scaled\" for col in scale_cols],\n",
    "    index=X_test.index\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "930c9bc5",
   "metadata": {},
   "source": [
    "## 4. Build the final DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f44646",
   "metadata": {},
   "source": [
    "We combine:\n",
    "all imputed numerical columns\n",
    "encoded \"type\"\n",
    "encoded \"province\"\n",
    "encoded \"subtype\"\n",
    "encoded \"state of building\"\n",
    "scaled numerical columns\n",
    "ALL remaining original categorical columns (including state_of_building if needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6785cd3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the original columns that were encoded or scaled\n",
    "drop_cols = [\"type\", \"province\", \"subtype\", \"state_of_building\"] + scale_cols\n",
    "\n",
    "X_train_base = X_train_cat.drop(columns=drop_cols)\n",
    "X_test_base = X_test_cat.drop(columns=drop_cols)\n",
    "\n",
    "# Build final DataFrames\n",
    "X_train_final = pd.concat([\n",
    "    X_train_base,\n",
    "    X_train_num,         # imputed original numericals\n",
    "    type_train_df,\n",
    "    province_train_df,\n",
    "    subtype_train_df,\n",
    "    state_train_df,\n",
    "    X_train_scaled\n",
    "], axis=1)\n",
    "\n",
    "X_test_final = pd.concat([\n",
    "    X_test_base,\n",
    "    X_test_num,\n",
    "    type_test_df,\n",
    "    province_test_df,\n",
    "    subtype_test_df,\n",
    "    state_test_df,\n",
    "    X_test_scaled\n",
    "], axis=1)\n",
    "\n",
    "# Show result\n",
    "X_train_final.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ed1246",
   "metadata": {},
   "source": [
    "# SINGLE UNIFIED SKLEARN PIPELINE WITH A COLUMNTRANSFORMER "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d25fcf37",
   "metadata": {},
   "source": [
    "This pipeline will automatically:\n",
    "* impute numeric columns (mean)\n",
    "* impute categorical columns (“state_of_building” → “unknown”)\n",
    "* OrdinalEncode state_of_building using your custom order\n",
    "* OneHotEncode type + province\n",
    "* LabelEncode subtype (inside a custom transformer)\n",
    "* scale selected numeric columns\n",
    "* output a fully-transformed DataFrame with all new columns\n",
    "* This is the clean, robust, and reusable solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc7abe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"1) Custom LabelEncoder Transformer\n",
    "Sklearn’s LabelEncoder only works for 1-D arrays, so we wrap it:\"\"\"\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "\n",
    "class LabelEncoderTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, column_name):\n",
    "        self.column_name = column_name\n",
    "        self.le = LabelEncoder()\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.le.fit(X[self.column_name])\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X_out = X.copy()\n",
    "        X_out[self.column_name + \"_le\"] = self.le.transform(X[self.column_name])\n",
    "        return X_out[[self.column_name + \"_le\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9798abf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Define column groups\"\"\"\n",
    "num_cols = [\"living_area (m²)\", \"number_of_bedrooms\", \"number_facades\", \"terrace_area (m²)\"]\n",
    "ohe_cols = [\"type\", \"province\"]\n",
    "ord_col = [\"state_of_building\"]\n",
    "label_col = [\"subtype\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d2ebed",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"3. Create the ColumnTransformer and Full Pipeline\"\"\"\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Custom order for state_of_building\n",
    "state_order = [\n",
    "    [\"unknown\", \"To demolish\", \"Under construction\", \"To restore\",\n",
    "     \"To renovate\", \"To be renovated\", \"Normal\", \"Fully renovated\",\n",
    "     \"Excellent\", \"New\"]\n",
    "]\n",
    "\n",
    "# ---- Pipelines ----\n",
    "\n",
    "# Numeric pipeline (mean impute + scale)\n",
    "num_pipeline = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"mean\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "# OneHotEncode pipeline for type + province\n",
    "ohe_pipeline = Pipeline(steps=[\n",
    "    (\"ohe\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False))\n",
    "])\n",
    "\n",
    "# OrdinalEncode pipeline for state_of_building\n",
    "ord_pipeline = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=\"unknown\")),\n",
    "    (\"ordinal\", OrdinalEncoder(categories=state_order))\n",
    "])\n",
    "\n",
    "# LabelEncoder pipeline for subtype (custom transformer)\n",
    "label_pipeline = Pipeline(steps=[\n",
    "    (\"labelenc\", LabelEncoderTransformer(\"subtype\"))\n",
    "])\n",
    "\n",
    "# ---- Combine into ColumnTransformer ----\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", num_pipeline, num_cols),\n",
    "        (\"ohe\", ohe_pipeline, ohe_cols),\n",
    "        (\"ord\", ord_pipeline, ord_col),\n",
    "        (\"label\", label_pipeline, label_col),\n",
    "    ],\n",
    "    remainder=\"drop\"\n",
    ")\n",
    "\n",
    "# Full pipeline\n",
    "full_pipeline = Pipeline(steps=[\n",
    "    (\"preprocessing\", preprocessor)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bead908d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"4. Fit and Transform: This returns a NumPy array — we convert it to a DataFrame with correct column names.\"\"\"\n",
    "X_train_transformed = full_pipeline.fit_transform(X_train)\n",
    "X_test_transformed = full_pipeline.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b348affc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"5. Output Column Names\n",
    "We reconstruct readable names:\"\"\"\n",
    "# 1. Numeric scaled columns\n",
    "num_features = num_cols\n",
    "\n",
    "# 2. One-hot encoded columns\n",
    "ohe_features = full_pipeline.named_steps[\"preprocessing\"] \\\n",
    "    .named_transformers_[\"ohe\"] \\\n",
    "    .named_steps[\"ohe\"] \\\n",
    "    .get_feature_names_out(ohe_cols)\n",
    "\n",
    "# 3. Ordinal encoded\n",
    "ord_features = [\"state_of_building_oe\"]\n",
    "\n",
    "# 4. Label encoded\n",
    "label_features = [\"subtype_le\"]\n",
    "\n",
    "# Combine\n",
    "all_features = list(num_features) + \\\n",
    "               list(ohe_features) + \\\n",
    "               ord_features + \\\n",
    "               label_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceebaebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"6. Final DataFrames\"\"\"\n",
    "X_train_final = pd.DataFrame(X_train_transformed, columns=all_features, index=X_train.index)\n",
    "X_test_final = pd.DataFrame(X_test_transformed, columns=all_features, index=X_test.index)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
